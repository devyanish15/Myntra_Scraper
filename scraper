import requests
from bs4 import BeautifulSoup
import json
import re
from urllib.parse import urljoin, urlparse
from django.conf import settings
import logging

logger = logging.getLogger(__name__)

class MyntraScraper:
    def __init__(self):
        self.session = requests.Session()
        # Set headers to mimic a real browser
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })

    def extract_product_data(self, url):
        """
        Extract product information from Myntra product URL
        
        Args:
            url (str): Myntra product URL
            
        Returns:
            dict: Product information including name, price, images, etc.
        """
        try:
            # Validate URL
            if not self._is_myntra_url(url):
                raise ValueError("Invalid Myntra URL")
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract product data from JSON-LD script tag
            json_data = self._extract_json_ld_data(soup)
            
            # Extract additional data from page elements
            product_data = {
                'url': url,
                'name': self._extract_product_name(soup, json_data),
                'brand': self._extract_brand(soup, json_data),
                'price': self._extract_price(soup, json_data),
                'original_price': self._extract_original_price(soup, json_data),
                'discount': self._extract_discount(soup),
                'images': self._extract_images(soup, json_data),
                'description': self._extract_description(soup),
                'sizes': self._extract_sizes(soup),
                'colors': self._extract_colors(soup),
                'rating': self._extract_rating(soup, json_data),
                'reviews_count': self._extract_reviews_count(soup),
                'category': self._extract_category(soup, json_data),
                'availability': self._extract_availability(soup),
                'product_id': self._extract_product_id(url, soup),
            }
            
            return product_data
            
        except requests.RequestException as e:
            logger.error(f"Request error while scraping {url}: {str(e)}")
            raise Exception(f"Failed to fetch product page: {str(e)}")
        except Exception as e:
            logger.error(f"Error while scraping {url}: {str(e)}")
            raise Exception(f"Failed to extract product data: {str(e)}")

    def _is_myntra_url(self, url):
        """Check if URL is a valid Myntra product URL"""
        parsed = urlparse(url)
        return 'myntra.com' in parsed.netloc

    def _extract_json_ld_data(self, soup):
        """Extract JSON-LD structured data from the page"""
        try:
            json_scripts = soup.find_all('script', type='application/ld+json')
            for script in json_scripts:
                try:
                    data = json.loads(script.string)
                    if isinstance(data, dict) and data.get('@type') == 'Product':
                        return data
                    elif isinstance(data, list):
                        for item in data:
                            if isinstance(item, dict) and item.get('@type') == 'Product':
                                return item
                except json.JSONDecodeError:
                    continue
            return {}
        except Exception:
            return {}

    def _extract_product_name(self, soup, json_data):
        """Extract product name"""
        # Try JSON-LD first
        if json_data.get('name'):
            return json_data['name'].strip()
        
        # Try various selectors
        selectors = [
            'h1.pdp-title',
            '.pdp-product-name',
            'h1[data-testid="product-title"]',
            '.product-title',
            'h1'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text(strip=True)
        
        return "Unknown Product"

    def _extract_brand(self, soup, json_data):
        """Extract brand name"""
        # Try JSON-LD first
        if json_data.get('brand', {}).get('name'):
            return json_data['brand']['name'].strip()
        
        # Try various selectors
        selectors = [
            '.pdp-brand-name',
            '.product-brand',
            '[data-testid="brand-name"]',
            '.brand-name'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text(strip=True)
        
        return "Unknown Brand"

    def _extract_price(self, soup, json_data):
        """Extract current selling price"""
        # Try JSON-LD first
        if json_data.get('offers', {}).get('price'):
            return float(json_data['offers']['price'])
        
        # Try various selectors
        selectors = [
            '.pdp-price strong',
            '.product-discountedPrice',
            '[data-testid="price"]',
            '.price-current'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                price_match = re.search(r'₹\s*(\d+(?:,\d+)*)', price_text)
                if price_match:
                    return float(price_match.group(1).replace(',', ''))
        
        return None

    def _extract_original_price(self, soup, json_data):
        """Extract original price (before discount)"""
        selectors = [
            '.pdp-mrp',
            '.product-strike',
            '[data-testid="original-price"]',
            '.price-original'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                price_match = re.search(r'₹\s*(\d+(?:,\d+)*)', price_text)
                if price_match:
                    return float(price_match.group(1).replace(',', ''))
        
        return None

    def _extract_discount(self, soup):
        """Extract discount percentage"""
        selectors = [
            '.pdp-discount',
            '.discount-percent',
            '[data-testid="discount"]'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                discount_text = element.get_text(strip=True)
                discount_match = re.search(r'(\d+)%', discount_text)
                if discount_match:
                    return int(discount_match.group(1))
        
        return None

    def _extract_images(self, soup, json_data):
        """Extract product images"""
        images = []
        
        # Try JSON-LD first
        if json_data.get('image'):
            if isinstance(json_data['image'], list):
                images.extend(json_data['image'])
            else:
                images.append(json_data['image'])
        
        # Try various selectors for additional images
        selectors = [
            '.image-grid-image img',
            '.product-images img',
            '[data-testid="product-image"] img',
            '.pdp-image img'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            for img in elements:
                src = img.get('src') or img.get('data-src')
                if src and src not in images:
                    if src.startswith('//'):
                        src = 'https:' + src
                    elif src.startswith('/'):
                        src = urljoin('https://myntra.com', src)
                    images.append(src)
        
        return list(set(images))  # Remove duplicates

    def _extract_description(self, soup):
        """Extract product description"""
        selectors = [
            '.product-description',
            '.pdp-product-description-content',
            '[data-testid="product-description"]',
            '.description-text'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text(strip=True)
        
        return None

    def _extract_sizes(self, soup):
        """Extract available sizes"""
        sizes = []
        selectors = [
            '.size-buttons-size-button',
            '.product-sizes .size',
            '[data-testid="size-option"]'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            for element in elements:
                size = element.get_text(strip=True)
                if size and size not in sizes:
                    sizes.append(size)
        
        return sizes

    def _extract_colors(self, soup):
        """Extract available colors"""
        colors = []
        selectors = [
            '.color-option',
            '.product-colors .color',
            '[data-testid="color-option"]'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            for element in elements:
                color = element.get('title') or element.get_text(strip=True)
                if color and color not in colors:
                    colors.append(color)
        
        return colors

    def _extract_rating(self, soup, json_data):
        """Extract product rating"""
        # Try JSON-LD first
        if json_data.get('aggregateRating', {}).get('ratingValue'):
            return float(json_data['aggregateRating']['ratingValue'])
        
        selectors = [
            '.index-overallRating div',
            '.product-rating',
            '[data-testid="rating"]'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                rating_text = element.get_text(strip=True)
                rating_match = re.search(r'(\d+\.?\d*)', rating_text)
                if rating_match:
                    return float(rating_match.group(1))
        
        return None

    def _extract_reviews_count(self, soup):
        """Extract number of reviews"""
        selectors = [
            '.index-ratingsCount',
            '.reviews-count',
            '[data-testid="reviews-count"]'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                count_text = element.get_text(strip=True)
                count_match = re.search(r'(\d+(?:,\d+)*)', count_text)
                if count_match:
                    return int(count_match.group(1).replace(',', ''))
        
        return None

    def _extract_category(self, soup, json_data):
        """Extract product category"""
        # Try JSON-LD first
        if json_data.get('category'):
            return json_data['category']
        
        # Try breadcrumb
        breadcrumb = soup.select('.breadcrumbs a')
        if breadcrumb:
            categories = [item.get_text(strip=True) for item in breadcrumb[1:]]  # Skip 'Home'
            return ' > '.join(categories)
        
        return None

    def _extract_availability(self, soup):
        """Check if product is in stock"""
        # Look for out of stock indicators
        out_of_stock_selectors = [
            '.out-of-stock',
            '.sold-out',
            '[data-testid="out-of-stock"]'
        ]
        
        for selector in out_of_stock_selectors:
            if soup.select_one(selector):
                return False
        
        # Look for add to bag button
        add_to_bag = soup.select_one('.pdp-add-to-bag, .add-to-cart, [data-testid="add-to-bag"]')
        return add_to_bag is not None

    def _extract_product_id(self, url, soup):
        """Extract product ID from URL or page"""
        # Try to extract from URL
        id_match = re.search(r'/(\d+)/buy', url)
        if id_match:
            return id_match.group(1)
        
        # Try to extract from page elements
        selectors = [
            '[data-product-id]',
            '[data-testid="product-id"]'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get('data-product-id') or element.get_text(strip=True)
        
        return None


# Django view/utility function
def scrape_myntra_product(url):
    """
    Utility function to scrape Myntra product data
    
    Args:
        url (str): Myntra product URL
        
    Returns:
        dict: Product information
    """
    scraper = MyntraScraper()
    return scraper.extract_product_data(url)


# Example usage in Django views
"""
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.views.decorators.csrf import csrf_exempt
import json

@csrf_exempt
@require_http_methods(["POST"])
def scrape_product(request):
    try:
        data = json.loads(request.body)
        url = data.get('url')
        
        if not url:
            return JsonResponse({'error': 'URL is required'}, status=400)
        
        product_data = scrape_myntra_product(url)
        return JsonResponse({'success': True, 'data': product_data})
        
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)
"""
